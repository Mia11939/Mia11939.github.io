<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title>Three-dimensional Human-computer Interaction Model Design for Chinese Pronunciation | Yayue Deng</title> <meta name="author" content="Yayue Deng"> <meta name="description" content="Three-dimensional Human-computer Interaction Model Design for Chinese Pronunciation"> <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="https://unpkg.com/bootstrap-table@1.21.4/dist/bootstrap-table.min.css"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.4.0/css/all.min.css" integrity="sha256-HtsXJanqjKTc8vVQjO4YMhiqFoXkfBsjBWcX91T1jr8=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="" id="highlight_theme_light"> <link href="https://cdn.rawgit.com/afeld/bootstrap-toc/v1.0.1/dist/bootstrap-toc.min.css" rel="stylesheet"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css"> <link rel="canonical" href="https://mia11939.github.io/blog/2021/3D/"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/native.css" media="none" id="highlight_theme_dark"> <script src="/assets/js/theme.js"></script> <script src="/assets/js/dark_mode.js"></script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"><span class="font-weight-bold">Yayue </span>Deng</a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about</a> </li> <li class="nav-item active"> <a class="nav-link" href="/blog/">Experience<span class="sr-only">(current)</span></a> </li> <link href="/assets/css/main_add.css" rel="stylesheet"> <link href="https://fonts.googleapis.com/css?family=Lato|Oswald" rel="stylesheet"> <li class="nav-item "> <a class="nav-link" href="/publications/">publications</a> </li> <li class="nav-item dropdown "> <a class="nav-link dropdown-toggle" href="#" id="navbarDropdown" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">cv</a> <div class="dropdown-menu dropdown-menu-right" aria-labelledby="navbarDropdown"> <a class="dropdown-item" href="/assets/pdf/cv_zh.pdf">cv_download</a> </div> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fas fa-moon"></i> <i class="fas fa-sun"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5"> <div class="row"> <div class="col-sm-3"> <nav id="toc-sidebar" class="sticky-top"></nav> </div> <div class="col-sm-9"> <div class="post"> <header class="post-header"> <h1 class="post-title">Three-dimensional Human-computer Interaction Model Design for Chinese Pronunciation</h1> <p class="post-meta">April 1, 2021</p> <p class="post-tags"> <a href="/blog/2021"> <i class="fas fa-calendar fa-sm"></i> 2021 </a>   ·   <a href="/blog/tag/human-computer-interaction"> <i class="fas fa-hashtag fa-sm"></i> Human-Computer-Interaction</a>   </p> </header> <article class="post-content"> <div id="markdown-content"> <h2 id="project-background">Project Background</h2> <p>In the context of the global outbreak of the COVID-19 virus, the development of artificial intelligence in the field of education is gaining momentum, and online teaching is gradually becoming a learning method that everyone is willing to accept. The new teaching method also poses new challenges to the traditional classroom teaching model. Traditional classroom pronunciation teaching mainly relies on teachers to demonstrate specific actions through language, teaching aids, or body, allowing students to comprehend on their own. This teaching method is highly ambiguous and difficult to meet the needs of online teaching and computer-assisted pronunciation teaching feedback.</p> <p>In terms of pronunciation teaching, in the absence of teaching aids and face-to-face demonstration and guidance from teachers, how to allow learners to quickly understand the essentials of phonetics learning and carry out effective imitation learning has become the direction of thinking for phonetics teachers under the new situation.</p> <p>In recent years, computer-assisted pronunciation teaching technology (CAPT) has begun to be applied in pronunciation teaching online platforms, and various attempts have been made to better give learners feedback on pronunciation problems. Feedback on pronunciation scores through GOP (Goodness of pronunciation) can help learners to a certain extent to recognize the pros and cons of their pronunciation. For example, feedback on pronunciation problems in the form of pronunciation attributes can make learners more clearly recognize where their pronunciation problems are and how to correct them. However, without the on-site guidance of the teacher, through textual descriptions or overly professional guidance methods, learners find it difficult to capture changes in key pronunciation parts, and even cannot understand the specific designation of various parts of the oral cavity, making it difficult to produce correct pronunciation.</p> <p>In terms of pronunciation phonetics research, some scholars have tracked the movement trajectories of the lips and tongue using EMA to obtain the lip and tongue dynamic data of each phoneme. From the perspective of pronunciation feedback, this method can reflect the oral changes of the target phoneme in a relatively intuitive way. However, the cost and difficulty of data collection and analysis in this way are high. The main manifestations are that the need to stick sensors to the specific positions of the speaker’s pronunciation organs will bring a strong discomfort to the speaker and affect the naturalness of pronunciation; the sensor electrodes fall off, which may cause data collection failure or inaccurate collection; the number of sensor electrodes is limited, and data modeling may face data sparsity and other problems. And the pronunciation data obtained in this way is difficult to analyze, and it is difficult to meet the flexible needs of pronunciation teaching.</p> <blockquote class="block-warning"> <p>This project is based on a three-dimensional anatomical model of the human head, creating animations and designing interactions in Unity. Considering the situation where the phonetic organs inside the mouth are not fully visible or completely invisible, we start from the perspective of visualizing the phonetic organs. We construct a visualized three-dimensional virtual human head and its oral system that can generate synchronous speech animations, in order to achieve the best effect in learning phonetics.</p> </blockquote> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <img src="/assets/img/3D/2.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <img src="/assets/img/3D/1.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <h2 id="practical-significance">Practical Significance</h2> <p>In response to the situation where the articulatory organs in the oral cavity are not fully visible or completely invisible, from the perspective of articulatory visualization, a three-dimensional virtual human head and its oral system capable of producing synchronized speech animation are constructed, so that the pronunciation method of Chinese phonetic symbols can be intuitively represented by a three-dimensional animation model. This project is based on a three-dimensional human head model, using knowledge of anatomy and pronunciation visualization to create a human oral anatomical simulation speech animation.</p> <ul> <li>Assisting in the classroom teaching of Chinese for international students studying in China. The visualization of this 3D virtual human head and its oral system through voice animation can aid teachers in classroom teaching, post-class evaluation feedback, and students’ online learning. By observing the way of vocalization in the simulated image animation, it can help Chinese learners master the correct way of vocalization.</li> <li>Helping in the teaching of Chinese pronunciation for children, the vivid 3D animation helps children understand and master Chinese pronunciation. At the same time, the 3D visualization of pronunciation, language teaching, and even human-computer interaction will play a positive role in promoting, with important theoretical significance and potential application prospects.</li> <li>For people with hearing impairments, they often cannot make a sound because they cannot hear the sound and do not know how to vocalize. The 3D visualized pronunciation animation solves this problem well, allowing people with hearing impairments to see how the vocal organs make sounds.</li> <li>The language problems of children with intellectual disabilities are becoming increasingly prominent. This system can be used to guide children with hearing impairments in tongue pronunciation position training. To overcome the invisibility problem in the tongue pronunciation movement process in the current language learning of children with hearing impairments, and improve the effect of pronunciation training for children with hearing impairments.</li> <li>At present, there is a lack of research on the visualization of Chinese pronunciation, especially through the visualization of three-dimensional models. Therefore, the generation of synchronized voice animation’s visualized 3D virtual human head and its oral system is very important in language learning, especially in second language learning and speech correction. In addition, this system can also be extended to the visualization of pronunciation teaching in English phonetics, Japanese fifty-sound chart, and so on.</li> </ul> <h2 id="project-content">Project Content</h2> <blockquote class="block-tip"> <p>Overall Goal: To construct a user-friendly, three-dimensional virtual human head and oral system that can generate synchronized voice animations.</p> </blockquote> <blockquote class="block-warning"> <p>In the aspect of animation </p> </blockquote> <ul> <li>Based on the muscle movements of human oral pronunciation, construct and design three-dimensional animations of the movements of each vocal organ.</li> <li>For vocal organs such as teeth, hard palate, and lower jaw that only undergo minor deformations or even no deformation during pronunciation, consider them as rigid bodies and simulate their movements. For vocal organs such as the tongue and soft palate that undergo significant deformations during pronunciation, attempt to simulate their deformation effects. By calling the Unity toolkit, simulate the movement of special soft muscles like the tongue.</li> <li>Meanwhile, in terms of data collection, we try to visualize the Chinese pronunciation process by driving a three-dimensional physiological model with data from a Chinese Electromagnetic Articulograph (EMA).</li> </ul> <blockquote class="block-warning"> <p>In the aspect of interaction design. </p> </blockquote> <ul> <li>Establish a basic interactive framework. Achieve human-computer interaction effects through script programming, including the movement and rotation of the head perspective, selective semi-transparency of muscles, and other interactions.</li> <li>Optimize voice animation and interaction process. For the situation where the pronunciation organs inside the mouth are not fully visible or completely invisible, from the perspective of visualization of the pronunciation organs, better interaction design is carried out on the model so that users can more clearly observe the movement of the pronunciation parts. Optimization of interaction includes: reserving interfaces, reducing the number of control points, adding visual comparison sections for Chinese and English pronunciation, and so on.</li> </ul> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <video src="/assets/video/3D_2.mp4" class="img-fluid rounded z-depth-1" width="auto" height="auto" controls=""></video> </figure> </div> </div> <div class="caption"> A Dynamic 3D Pronunciation Teaching Model Example </div> <h2 id="innovation-description">Innovation Description</h2> <ul> <li>Combining knowledge in the field of anatomy, a pronunciation feedback system has been developed. A professional anatomical human head model is used for the simulation and teaching of Chinese pronunciation. The pronunciation animation is based on a physiological anatomical three-dimensional model, involving the simulation of the movement of the pronunciation organs in the oral cavity. For pronunciation organs such as teeth, hard palate, and lower jaw, which only produce minor shape changes or even no shape changes during pronunciation, they are treated as rigid bodies and simulated by movements such as rotation and scaling. For pronunciation organs such as the tongue and soft palate, which produce a large amount of shape changes during pronunciation, the Free-Form Deformation (FFD) attribute is added to simulate their shape change effects.</li> <li>Innovation in application scenarios. There are almost no Chinese teaching software or programs on the market based on three-dimensional human head anatomical models, most of them are two-dimensional teaching animations. The changes in the most important pronunciation organ in the oral cavity - the tongue, cannot be seen when simulated with two-dimensional animations or real people. Now, we have incorporated knowledge of anatomy to create a user-friendly interactive Chinese pronunciation simulation system to achieve precise simulation effects. So far, no one has done this, and we have currently implemented basic vocal animations and simple interactions using Unity technology.</li> <li>This project applies anatomical three-dimensional animation to the scenario of Chinese language teaching, realizing innovation in application scenarios.</li> </ul> </div> </article> <br> <hr> <br> <ul class="list-disc pl-8"></ul> <h2 class="text-3xl font-semibold mb-4 mt-12">Enjoy Reading This Article?</h2> <p class="mb-2">Here are some more articles you might like to read next:</p> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2023/CSS/">Conversational Speech Synthesis</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2022/ESS/">Rhythm-controllable Speech Synthesis</a> </li> </div> </div> </div> </div> <footer class="fixed-bottom"> <div class="container mt-0"> © Copyright 2023 Yayue Deng. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.bundle.min.js" integrity="sha256-fgLAgv7fyCGopR/gBNq2iW3ZKIdqIcyshnUULC4vex8=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.8/dist/medium-zoom.min.js" integrity="sha256-7PhEpEWEW0XXQ0k6kQrPKwuoIomz8R8IYyuU1Qew4P8=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js"></script> <script defer src="https://cdn.rawgit.com/afeld/bootstrap-toc/v1.0.1/dist/bootstrap-toc.min.js"></script> <script defer src="https://unpkg.com/bootstrap-table@1.21.4/dist/bootstrap-table.min.js"></script> <script src="/assets/js/no_defer.js"></script> <script defer src="/assets/js/common.js"></script> <script defer src="/assets/js/copy_code.js" type="text/javascript"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>